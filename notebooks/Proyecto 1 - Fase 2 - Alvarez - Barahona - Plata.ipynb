{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65486335",
   "metadata": {},
   "source": [
    "### María Sofía Álvarez - Brenda Barahona - Álvaro Plata\n",
    "<h1 align='center'>Proyecto 1: Analítica de textos - Preprocesamiento</h1>\n",
    "\n",
    "En esta fase del proyecto, nos encargaremos de construir las pipelines necesarias para desplegar nuestros modelos en una API. Para ello, únicamente nos remitiremos a construir los 3 modelos que nos dieron los mejores resultados en la fase 1 de este proyecto, después de realizar el ajuste de hiperparámetros desarrollado en la fase anterior. Este notebook se divide en ciertas fases. Primero, se realiza todo el preprocesamiento, que es común a todos los modelos. Segundo, se terminan de construir las pipelines propias de cada modelo, de acuerdo con los hiperparámetros que fueron ajustados en la fase 1 (solo con ellos, para ahorrar tiempo de cómputo). Por último, se exportan los tres modelos.\n",
    "\n",
    "Si desea ver a fondo alguna parte del perfilamiento, preprocesamiento de datos realizado, o ajuste de hiperparámetrod, remítase al repositorio de github de la fase 1 de este proyecto, disponible en <a href=\"https://github.com/sofiaalvarezlopez/Proyecto-1-BI\">este link</a>.\n",
    "\n",
    "## Importación de librerías\n",
    "Importamos las librerías necesarias para el desarrollo de este proyecto. Las librerías instaladas son exactamente las mismas que las que se instalaron para la fase 1 de este proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aee7fd68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ESAI\n",
    "import re\n",
    "import nltk\n",
    "import keras\n",
    "import spacy\n",
    "import inflect\n",
    "import sent2vec # Para descargar esta libreria, es necesario descargarla desde GitHub https://github.com/epfml/sent2vec\n",
    "import stopwords\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import contractions\n",
    "import seaborn as sns\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "import pandas_profiling as pp\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.utils import resample, class_weight\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from sklearn.metrics import precision_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from clases import Preprocessing, StemAndLemmatize, VectorizeLSTM, LSTMBuilder\n",
    "from keras.layers import LSTM, Dense, Embedding, TextVectorization, Input, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283a6d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a37bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e4e61",
   "metadata": {},
   "source": [
    "Procedemos, entonces, a ver los datos suministrados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c40049",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses =pd.read_csv('ApoyoDiagnosticoEstudiante/medical_text_clasificacion.csv')\n",
    "X, Y = diagnoses.drop(['problems_described'], axis=1), diagnoses['problems_described']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,stratify=Y,test_size=0.01, random_state=28)\n",
    "data_train = pd.concat( [X_train, Y_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b10797",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "Iniciamos con la fase de preprocesamiento de los datos:\n",
    "### Extracción de entidades médicas\n",
    "De acuerdo con [4], para clasificación en contextos médicos es útil extraer entidades médicas para la clasificación, como se hizo en el proyecto pasado. No obstante, se obtuvieron mejores resultados con las entidades en todos los casos, así que se omitirá este pedazo:\n",
    "```python\n",
    "nlp = en_ner_bionlp13cg_md.load()\n",
    "def medical_entities(text):\n",
    "    entities = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    return ' '.join(entities)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7000e9a9",
   "metadata": {},
   "source": [
    "### Manejo de Ruido \n",
    "En esta sección se quitará o modificará todo lo que se considere como ruido:\n",
    "\n",
    "+ Caracteres no ascii: Hace parte importante del preprocesamiento de las palabras. Con caracteres no-ascii, el preprocesamiento puede verse terriblemente perjudicado.\n",
    "+ Se pasará de mayusculas a minusculas: Asimismo, es importante que todas las palabras tengan una capitalización homogénea (en este caso, queremos que estén en minúscula).\n",
    "+ Se eliminará la puntuación: Por otro lado, consideramos que la puntuación no provee información adicional en este contexto. Adicionalmente, de no eliminarse, puede aumentar la dimensionalidad de los datos sin proveer más información. Por ejemplo, no tiene sentido pensar que \"almuerzo!\" y \"almuerzo\" sean palabras diferentes. Por ello removemos toda la puntuación usando expresiones regulares.\n",
    "+ Se reemplazarán los números: Ahora, podemos suponer que los números no proveen información relevante para el problema en cuestión. Estos pueden también agregar dimensionalidad inutilmente al problema.\n",
    "+ Se quitarán las fechas (si las hay) también: las fechas son irrelevantes para el contexto del problema.\n",
    "+ Se quitarán las palabras vacias (artículos, pronombres, preposiciones): Estas se denominan stop-words, en inglés. Son palabras que se usan en muchos contextos (como 'the') y no aportan información significativa en la construcción del modelo. Asimismo, definimos nuestras propias stopwords de acuerdo con el perfilamiento realizado, pues son palabras que no aportan significativamente al contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbfe53",
   "metadata": {},
   "source": [
    "```python\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "    \n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_numbers(words):\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub('\\d+.*', '', word)\n",
    "        if not word.isnumeric() and new_word != '':\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_dates(words):\n",
    "    \"\"\"Replace all dates in our data\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'\\d+/\\d+/\\d+', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4f7dc",
   "metadata": {},
   "source": [
    "De todas estas palabras, encontramos que solamente tumor y lesion pueden ser relevantes para nuestro análisis. Por lo tanto, las quitamos todas, excepto estas dos. Además, en un análisis preliminar encontramos otras palabras irrelevantes, las cuales también eliminamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfbd103",
   "metadata": {},
   "source": [
    "```python\n",
    "#En una primera iteracion nos dimos cuenta que las palabras \"paty\", \"patients\" aparece frecuentemente en todas las enfermedades,\n",
    "#estos serán eliminados por que no agregan información valiosa. \n",
    "our_stopwords = [\"paty\",\"patients\",\"p\",\"study\",\"result\", \"human\", \"humans\", \"monkey\", \"monkeys\", \n",
    "                 \"diseases\", \"studied\",\"first\", \"rat\", \"patient\", \"case\", \"p less\", \"treatment\", \n",
    "                 \"group\", \"associated\", \"result\", \"may\", \"effect\", \"compared\", \"use\", \"cases\", \"year\", \n",
    "                 \"years\", \"age\", \"study\", \"disease\", \"found\", \"normal\", \"month\", \"although\", \"per cent\",\n",
    "                 \"one\", \"two\", \"three\", \"four\", \"n\", \"children\", \"women\"]\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english') and word not in our_stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "```\n",
    "Asimismo, tenemos la función de eliminación del ruido global:\n",
    "\n",
    "``` python\n",
    "def noise_elimination(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_numbers(words)\n",
    "    words = remove_dates(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa899a0e",
   "metadata": {},
   "source": [
    "Con esto, ya tenemos casi listo nuestro proceso de eliminación del ruido. Primero, llamamos a la función <code>fix</code> de la librería ```contraction``` para aquellas contracciones que no están separadas en dos palabras. Esta elimina todas las ocurrencias de contracciones en inglés, reemplazándolas por su equivalente sin contracción. Una vez realizado este paso, \"tokenizamos\" las historias clínicas. Para poder evaluar cada palabra por separado y aplicar los pasos de preprocesamiento, hacemos la tokenización en palabras individuales usando el módulo ```word_tokenize```. Finalmente, aplicamos la función```noise_elimination``` definida previamente.\n",
    "\n",
    "Más adelante, lo que realmente nos servirá será volver a tener los documentos sin tokenización para el proceso de vectorización (sea tf-idf, o BioSentVec, como se vera mas adelante). Entonces, volvemos a juntar todas las palabras para cada documento y retornamos eso. También retornamos las palabras tokenizadas con el fin de realizar la lematización estemización más adelante.\n",
    "\n",
    "Note que estas funciones las aplicamos tanto sobre los medical abstracts iniciales, como las palabras clave que obtuvimos con la librería de SpaCy descrita previamente.\n",
    "\n",
    "```python\n",
    "def preprocessing(X):\n",
    "    new_X_train= X.apply(contractions.fix) #Aplica la corrección de las contracciones\n",
    "    new_X_train = new_X_train.apply(word_tokenize)\n",
    "    new_X_train = new_X_train.apply(noise_elimination) #Aplica la eliminación del ruido\n",
    "    X_train = new_X_train.apply(lambda x: ' '.join(map(str, x)))\n",
    "    return new_X_train, X_train\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8450b0",
   "metadata": {},
   "source": [
    "### Normalización: Stemming y Lemmatization \n",
    "Aplicaremos tecnicas como \"Stemming\" y \"Lemmatization\" sobre la columna \"medical_abstracts\". \n",
    "\n",
    "En esta parte del preprocesamiento, hacemos una eliminación de prefijos y sufijos, así como una lematización de los verbos. En el caso del Stemming hay varios algoritmos que podemos utilizar: Porter, Snowball (Porter2) o Lancaster (Paice-Husk). De acuerdo a lo que encontramos,  <a href=\"https://stackoverflow.com/questions/10554052/what-are-the-major-differences-and-benefits-of-porter-and-lancaster-stemming-alg\"> la agresividad en el corte de raíces de las palabras de estos algoritmos aumenta, siendo Porter el menos agresivo y Lancaster el más agresivo </a>. En este sentido, parece ser que Lancaster (a pesar de ser el más eficiente de todos), puede ser poco riguroso y así crear muchas ambigüedades. Asimismo, Porter2 es un poco más agresivo que Porter, sin perder mucho el origen de las palabras y con un tiempo de cómputo razonable. El mismo Porter, creador del algoritmo, argumenta que es una mejora de su algoritmo original. Con el fin de tener la mejor preparación de las palabras, en un tiempo de cómputo razonable, decidimos usar Porter2. En el caso de la lematización, sí usamos WordNetLemmatizer() al ser el más usado en el mundo del procesamiento de textos.\n",
    "```python\n",
    "#Funciones de \"Stemming\" y \"Lemmatization\"\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems + lemmas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb6ca9",
   "metadata": {},
   "source": [
    "Y creamos la clase correspondiente para las funciones:\n",
    "``` python\n",
    "class StemAndLemmatize():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def transform(self,X,y=None):\n",
    "        X[\"medical_abstracts\"] = X[\"medical_abstracts\"].apply(stem_and_lemmatize)\n",
    "        return X\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5759a7d",
   "metadata": {},
   "source": [
    "Finalmente, con todas las funciones definidas, creamos el pipeline de preprocesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9e2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = [\n",
    "    (\"preprocessing\", Preprocessing()),\n",
    "    (\"stem_lemmatize\", StemAndLemmatize())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45eea7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe  = Pipeline(preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137bfd99",
   "metadata": {},
   "source": [
    "Veamos una muestra de los textos preprocesados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68008d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_abstracts</th>\n",
       "      <th>problems_described</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>[threedimension, system, longterm, cultur, col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>[brainstem, auditori, evok, respons, acoust, n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>[methodolog, mental, stress, test, cardiovascu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9568</th>\n",
       "      <td>[applic, modifi, bioassay, monitor, serum, tei...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10074</th>\n",
       "      <td>[fine, surfac, structur, intraspin, neurenter,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       medical_abstracts  problems_described\n",
       "4888   [threedimension, system, longterm, cultur, col...                   1\n",
       "3247   [brainstem, auditori, evok, respons, acoust, n...                   3\n",
       "5261   [methodolog, mental, stress, test, cardiovascu...                   4\n",
       "9568   [applic, modifi, bioassay, monitor, serum, tei...                   5\n",
       "10074  [fine, surfac, structur, intraspin, neurenter,...                   5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_train_procesados = pipe.fit_transform(data_train, data_train['problems_described'])\n",
    "datos_train_procesados.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c509b0",
   "metadata": {},
   "source": [
    "Finalmente, almacenamos los datos de entrenamiento en un archivo <code>.csv</code> denominado: <code>proyecto1_fase2_datos_entrenamiento.csv</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e075174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_train_procesados.to_csv(\"proyecto1_fase2_datos_preprocesados.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece05ab",
   "metadata": {},
   "source": [
    "## Modelo: LSTM\n",
    "En la iteración pasada, diseñamos tres algoritmos de Machine Learning para probar: Naïve-Bayes, OneVsRest y una red neuronal usando una LSTM (Long-Short Term Memory). De estos, el que mejores métricas arrojó fue el LSTM. Por lo tanto, debido a que buscamos optimizar la precisión de nuestro modelo para el cliente, este es el que desplegaremos en la API. Si desea ver más información acerca de la LSTM, remítase al repositorio del proyecto anterior.\n",
    "\n",
    "La LSTM (Long-Short Term Memory) es un tipo de red neuronal recurrente (RNN, por sus siglas en inglés) que se desempeña mejor que las RNN tradicionales en términos de memoria [1]. Una RNN es un tipo de red neuronal que permite a las salidas de capas previas ser utilizadas como entradas, teniendo estados ocultos [2].\n",
    "\n",
    "Las LSTM tienen múltiples capas ocultas. A medida que se pasa a través de una capa, la información relevante se mantiene y la irrelevante se desecha en cada neurona (celda) individual [1]. Asimismo, las LSTM solucionan el problema de desvanecimiento de gradientes que las RNN enfrentan a menudo.\n",
    "\n",
    "Las LSTM cuentan principalmente con 3 compuertas:\n",
    "+ **FORGET Gate:** Esta compuerta es la responsable de decidir qué información se queda y cuál es irrelevante y debe descartarse. Para ello, utiliza la información que viene de la neurona anterior $h_{t-1}$ y la información de la celda actual, $x_t$. Sobre ellas, se corre una función sigmoide, $$S(x) = \\frac{1}{1 + e^{-x}},$$ tal que los datos que tiendan a 0 son descartados por la red [1].\n",
    "+ **INPUT Gate:** Esta compuerta actualiza el estado de la neurona y decide qué información es importante. Como la compuerta FORGET ayuda a descartar la información, la compuerta INPUT ayuda a encontrar la información importante y a almacenar ciertos datos relevantes en memoria. En este caso, la información de la neurona anterior, $h_{t-1}$ es pasada por una función de activación sigmoide, mientras que la información de la neurona actual $x_t$ se pasa por una función de activación de tangete hiperbólica: $$\\tanh(x) = \\frac{1 - e^{-2x}}{1 + e^{-2x}}.$$ Es importante resaltar que la función $\\tanh$ ayuda a regular la red y a reducir el sesgo de la misma [1].\n",
    "+ **OUTPUT Gate:** Tras multiplicar el estado actual de la neurona con lo que se obtiene de la compuerta FORGET, lo cual permite eliminar cierta información si la compuerta FORGET arroja pesos de 0, debe decidirse cual será el estado de la siguiente celda. La información de $h_{t-1}$ y $x_t$ se pasa a través de una función sigmoide, el cual es a su vez pasado por una función de tangente hiperbólica, y ambos resultados se mltiplican para decidir la información que llevará el estado oculto [1]. \n",
    "\n",
    "A continuación, puede verse la gráfica de las funciones $\\tanh$ y sigmoide:\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Muhammad-Hamdan-8/publication/327435257/figure/fig4/AS:742898131812354@1554132125449/Activation-Functions-ReLU-Tanh-Sigmoid.ppm\" />\n",
    "\n",
    "Note que también se encuentra la función de activación ReLU (Regularized Linear Unit), muy popular en las aplicaciones de Machine y Deep Learning.\n",
    "\n",
    "Asimismo, puede verse una representación esquemática (obtenida de [3]) de la estructura de cada una de las compuertas:\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Xuan_Hien_Le2/publication/334268507/figure/fig8/AS:788364231987201@1564972088814/The-structure-of-the-Long-Short-Term-Memory-LSTM-neural-network-Reproduced-from-Yan.png\" width=50% />\n",
    "\n",
    "En la imagen podemos ver las funciones de activación usadas en cada celda LSTM (sigmoide y tangente hiperbólica), así como sus entradas, salidas y compuertas.\n",
    "\n",
    "Finalmente, procedemos a volver a leer los datos para realizar el preprocesamiento desde 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0c73d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses =pd.read_csv('ApoyoDiagnosticoEstudiante/medical_text_clasificacion.csv')\n",
    "X, Y = diagnoses.drop(['problems_described'], axis=1), diagnoses['problems_described']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,stratify=Y,test_size=0.01, random_state=28)\n",
    "data_train = pd.concat( [X_train, Y_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fbef43",
   "metadata": {},
   "source": [
    "### Manejo de desbalanceo de las clases\n",
    "\n",
    "Ahora, uno de los mayores problemas de la clasificación es el contexto desbalanceado. Una opción sería reducir el conjunto de datos hasta que todas las clases queden con un número de abstracts igual al tamaño de la clase de menor cantidad de abstracts. No obstante, por lo general la idea es no reducir el conjunto de datos. Otra opción, como en los algoritmos anteriores, sería usar SMOTE. No obstante, esto es computacionalmente muy costoso para la red.\n",
    "\n",
    "Lo que sí podemos hacer es considerar pesos. Así, el modelo podrá prestar mayor atención a las clases minoritarias. Para ello, usaremos la librería de <code>sk-learn</code> y lo pasaremos como un objeto al modelo que construiremos más adelante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b8e215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "                class_weight = 'balanced',\n",
    "                classes = np.unique(Y_train), \n",
    "                y = Y_train)\n",
    "train_class_weights_ = dict(enumerate(class_weights, start=1))\n",
    "train_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640f129",
   "metadata": {},
   "source": [
    "Podemos ver los pesos asociados a cada una de las clases, en orden ascendente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "428e1e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.9127929312331925,\n",
       " 2: 1.9332790886899918,\n",
       " 3: 1.5,\n",
       " 4: 0.946236559139785,\n",
       " 5: 0.6010624841892234}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b607b",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0b2f3",
   "metadata": {},
   "source": [
    "Usando el modelo de vectorización de BioSentVec, se obtuvo, utilizando la búsqueda de hiperparámetros, que el mejor modelo era aquel que no tenía ninguna capa adicional a las consideradas inicialmente (dos capas LSTM con sus respectivas capas de dropout), un dropout de 0.1 (i.e. una tasa de pérdida bastante pequeña) y cada una de las capas con 64 neuronas.\n",
    "\n",
    "Finalmente, se tiene una capa softmax con 5 neuronas, que corresponden con las 5 clases del problema. Es importante mencionar que la variable categórica Y se debe convertir a la funcionalidad de Keras para el correcto funcionamiento de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32e67bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data_train.drop(['problems_described'], axis=1), data_train['problems_described']\n",
    "Y = keras.utils.np_utils.to_categorical(Y)[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f23e8",
   "metadata": {},
   "source": [
    "Y, por último, creamos la vectorización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5220a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps.append(('vectorizer', VectorizeLSTM()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2efa8",
   "metadata": {},
   "source": [
    "Veamos qué tiene la pipeline hasta ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66dbcae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 <clases.Preprocessing object at 0x7fde44fc8940>),\n",
       "                ('stem_lemmatize',\n",
       "                 <clases.StemAndLemmatize object at 0x7fde44fc88e0>),\n",
       "                ('vectorizer',\n",
       "                 <clases.VectorizeLSTM object at 0x7fde19467400>)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c379290",
   "metadata": {},
   "source": [
    "Finalmente, creamos un clasificador de Keras usando el modelo de la red, de acuerdo con los hiperparámetros encontrados en el anterior proyecto:\n",
    "```python\n",
    "class LSTMBuilder():\n",
    "    def __call__(self):\n",
    "        output=5\n",
    "        model = Sequential(name=\"LSTM\")\n",
    "        # Agregamos una capa LSTM con el tamanio de entrada de los embedded abstracts y 64 neuronas en la capa\n",
    "        model.add(LSTM(units=64, return_sequences=True, \n",
    "                    input_shape=(1, 700)))\n",
    "        model.add(Dropout(0.1))\n",
    "        # Agregamos una segunda capa LSTM con 16 neuronas\n",
    "        model.add(LSTM(units=64, return_sequences=False))\n",
    "        # Con su respectiva capa de dropout\n",
    "        model.add(Dropout(0.1))\n",
    "        # Definimos la capa de salida\n",
    "        model.add(Dense(output, activation='softmax'))\n",
    "        # Compilo\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras.metrics.Precision(name='precision')])\n",
    "        return model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b208f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KerasClassifier(LSTMBuilder(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a86574ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps.append((('model', clf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33163a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfuly loaded\n",
      "Epoch 1/50\n",
      "368/368 [==============================] - 9s 5ms/step - loss: 1.0151 - precision: 0.6461 - val_loss: 0.8863 - val_precision: 0.7128\n",
      "Epoch 2/50\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 0.8135 - precision: 0.6559 - val_loss: 0.8222 - val_precision: 0.7576\n",
      "Epoch 3/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.7740 - precision: 0.6597 - val_loss: 0.7895 - val_precision: 0.7404\n",
      "Epoch 4/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.7494 - precision: 0.6686 - val_loss: 0.8041 - val_precision: 0.7048\n",
      "Epoch 5/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.7305 - precision: 0.6675 - val_loss: 0.7951 - val_precision: 0.7333\n",
      "Epoch 6/50\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 0.7134 - precision: 0.6755 - val_loss: 0.7938 - val_precision: 0.7255\n",
      "Epoch 7/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.7042 - precision: 0.6733 - val_loss: 0.7959 - val_precision: 0.6972\n",
      "Epoch 8/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.6834 - precision: 0.6790 - val_loss: 0.7996 - val_precision: 0.6903\n",
      "Epoch 9/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.6780 - precision: 0.6815 - val_loss: 0.8071 - val_precision: 0.7027\n",
      "Epoch 10/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.6631 - precision: 0.6813 - val_loss: 0.8253 - val_precision: 0.7308\n",
      "Epoch 11/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.6529 - precision: 0.6875 - val_loss: 0.7990 - val_precision: 0.7130\n",
      "Epoch 12/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.6433 - precision: 0.6891 - val_loss: 0.7886 - val_precision: 0.7000\n",
      "Epoch 13/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.6288 - precision: 0.6936 - val_loss: 0.8091 - val_precision: 0.6875\n",
      "Epoch 14/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.6185 - precision: 0.6956 - val_loss: 0.8644 - val_precision: 0.6842\n",
      "Epoch 15/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.6068 - precision: 0.7004 - val_loss: 0.8054 - val_precision: 0.7273\n",
      "Epoch 16/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.5975 - precision: 0.7033 - val_loss: 0.8245 - val_precision: 0.7117\n",
      "Epoch 17/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.5859 - precision: 0.7063 - val_loss: 0.8537 - val_precision: 0.6897\n",
      "Epoch 18/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.5784 - precision: 0.7138 - val_loss: 0.9376 - val_precision: 0.6944\n",
      "Epoch 19/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.5666 - precision: 0.7146 - val_loss: 0.8339 - val_precision: 0.7207\n",
      "Epoch 20/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.5562 - precision: 0.7224 - val_loss: 0.8773 - val_precision: 0.6903\n",
      "Epoch 21/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.5519 - precision: 0.7192 - val_loss: 0.8371 - val_precision: 0.7143\n",
      "Epoch 22/50\n",
      "368/368 [==============================] - 1s 3ms/step - loss: 0.5374 - precision: 0.7258 - val_loss: 0.9217 - val_precision: 0.6696\n",
      "Epoch 22: early stopping\n"
     ]
    }
   ],
   "source": [
    "pipe_elegida = pipe.fit(X, Y, \n",
    "                        model__class_weight=train_class_weights,\n",
    "                        model__callbacks=EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto', baseline=None),\n",
    "                        model__validation_split=0.01, \n",
    "                        model__epochs= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2294c1c",
   "metadata": {},
   "source": [
    "### Prueba de la calidad del modelo\n",
    "Veamos la matriz de confusión y otras métricas pertinentes para este modelo. Para un análisis más exhaustivo, remítase al anterior proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "831e5eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reporte para el modelo construido---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.87      0.80      2603\n",
      "           2       0.53      0.91      0.67      1229\n",
      "           3       0.56      0.86      0.67      1584\n",
      "           4       0.72      0.81      0.76      2511\n",
      "           5       0.84      0.31      0.45      3953\n",
      "\n",
      "    accuracy                           0.67     11880\n",
      "   macro avg       0.68      0.75      0.67     11880\n",
      "weighted avg       0.72      0.67      0.65     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe_elegida.predict(X) + 1 # Sumamos 1 para que las clases nos queden entre 1 y 5 \n",
    "Y_tr = Y.argmax(1) + 1 # Sumamos 1 para que las clases nos queden entre 1 y 5 \n",
    "\n",
    "print('---Reporte para el modelo construido---')\n",
    "print(classification_report(Y_tr, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eb6601",
   "metadata": {},
   "source": [
    "Podemos ver que, en promedio, la precisión de este modelo no es mala. De hecho, para tres de las 5 clases (neoplasias, enfermedades cardiovasculares y patologías generales, se tiene una precisión mayor o igual al 70%. Esperamos poder mejorar esto de alguna forma, para ello, intentamos otras técnicas.\n",
    "\n",
    "Veamos ahora la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2bf08d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_tr, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels= np.arange(1,6))\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1876b68d",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que la clase que más se confunde es la 5: esto tiene sentido, pues las palabras que la conforman pueden caber en varias de las otras categorías. De resto, el modelo clasifica bien (sin mucho error) las otras clases. Note que las clases peor clasificadas son las minoritarias, incluso a pesar de que consideramos los pesos en la construcción del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8bf6b2",
   "metadata": {},
   "source": [
    "### Obtención de las estadísticas\n",
    "Veamos la probabilidad de que un texto determinado pertenezca a cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45a21d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfuly loaded\n"
     ]
    }
   ],
   "source": [
    "pred = pipe_elegida.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e1e5f",
   "metadata": {},
   "source": [
    "Veamos si las probabilidades coinciden con lo que la etiqueta, para el primer dato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f6fddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase predicha es: 1 con una probabilidad de 83.55962038040161%\n",
      "La clase real es 1\n"
     ]
    }
   ],
   "source": [
    "predicha_0 = np.argmax(pred[0])+1\n",
    "real_0 = Y_tr[0]\n",
    "print('La clase predicha es: {} con una probabilidad de {}%'.format(predicha_0, np.max(pred[0])*100) )\n",
    "print('La clase real es {}'.format(real_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444542f9",
   "metadata": {},
   "source": [
    "Vemos que, para este dato en particular, la clase predicha y la real es la misma. Asimismo, la clase predicha tiene una buena probabilidad. El conocimiento de las probabilidades puede ser útil en el dominio médico porque permite al médico tener un segundo concepto, con una probabilidad menor, en caso de que el primero no lo satisfaga del todo. Es particularmente útil en el caso de las enfermedades tipo 5 (patologías generales), qu pueden confundirse como otro tipo de enfermedades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b9e6fc",
   "metadata": {},
   "source": [
    "### Exportación del modelo\n",
    "Una vez entrenado el modelo, procedemos a guardarlo y exportarlo. Debido a que no existe una manera directa de almacenar un modelo de keras dentro de una pipeline de scikit learn, es necesario guardarlos por separado. Así, guardamos primero el modelo de Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95e1091b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./assets/modelo.pkl']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_elegida.named_steps['model'].model.save('./assets/keras_model.h5')\n",
    "pipe_elegida.named_steps['model'].model = None\n",
    "dump(pipe_elegida, './assets/modelo.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d2d0c1",
   "metadata": {},
   "source": [
    "<h2 id='bibliografia'>Bibliografía</h2>\n",
    "\n",
    "---\n",
    "\n",
    "<a id='geron'>[1]</a> Géron, A. (2017). Hands-on machine learning with Scikit-Learn and TensorFlow : concepts, tools, and techniques to build intelligent systems. Sebastopol, CA: O'Reilly Media. ISBN: 978-1491962299\n",
    "\n",
    "<a id='nlp_profiler'>[2]</a> https://towardsdatascience.com/nlp-profiler-profiling-datasets-with-one-or-more-text-columns-9b791193db89\n",
    "\n",
    "[3] https://www.kaggle.com/code/neomatrix369/nlp-profiler-simple-dataset/notebook\n",
    "\n",
    "[4] Clinical Text Classification: https://www.kaggle.com/ritheshsreenivasan/clinical-text-classification\n",
    "\n",
    "[5] https://www.analyticsvidhya.com/blog/2021/06/lstm-for-text-classification/\n",
    "\n",
    "[6] https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks\n",
    "\n",
    "[7] Application of Long Short-Term Memory (LSTM) Neural Network for Flood Forecasting - Scientific Figure on ResearchGate. Available from: https://www.researchgate.net/figure/The-structure-of-the-Long-Short-Term-Memory-LSTM-neural-network-Reproduced-from-Yan_fig8_334268507 [accessed 28 Mar, 2022]\n",
    "\n",
    "[8] Zhang Y, Chen Q, Yang Z, Lin H, Lu Z. BioWordVec, improving biomedical word embeddings with subword information and MeSH. Scientific Data. 2019.\n",
    "\n",
    "[9] https://towardsdatascience.com/simplified-math-behind-dropout-in-deep-learning-6d50f3f47275\n",
    "\n",
    "[10] https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
    "\n",
    "[11] https://towardsdatascience.com/7-tips-to-choose-the-best-optimizer-47bb9c1219e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30ef49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
